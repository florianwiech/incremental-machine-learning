{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network with tensorflow on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import gzip, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images:  (60000, 28, 28)\n",
      "train labels:  (60000, 10)\n",
      "test images:  (10000, 784)\n",
      "test labels:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "\n",
    "with gzip.open('mnist.pkl.gz', 'rb') as f:\n",
    "    ((traind,trainl),(vald,vall),(testd,testl))=pickle.load(f, encoding='bytes')\n",
    "    traind = traind.astype(\"float32\").reshape(-1,28,28)\n",
    "    trainl = trainl.astype(\"float32\")\n",
    "    testd = testd.astype(\"float32\").reshape(-1,28,28)\n",
    "    testl = testl.astype(\"float32\")\n",
    "\n",
    "# traind = traind.reshape(-1,784) \n",
    "testd = testd.reshape(-1,784)\n",
    "\n",
    "print(\"train images: \", traind.shape)\n",
    "print(\"train labels: \", trainl.shape)\n",
    "\n",
    "print(\"test images: \", testd.shape)\n",
    "print(\"test labels: \", testl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes 0-4, images:  (30596, 10)\n",
      "classes 0-4, labels:  (30596, 784)\n",
      "classes 5-9, images:  (29404, 10)\n",
      "classes 5-9, labels:  (29404, 784)\n"
     ]
    }
   ],
   "source": [
    "# split MNIST\n",
    "\n",
    "# classes 0-4\n",
    "classVector = trainl.argmax(axis=1)\n",
    "class01234Mask = np.logical_or((classVector == 0), \n",
    "                               np.logical_or((classVector == 1), \n",
    "                               np.logical_or((classVector == 2), \n",
    "                               np.logical_or((classVector == 3), \n",
    "                                             (classVector == 4)))))\n",
    "\n",
    "trainl_01234 = trainl[class01234Mask]\n",
    "traind_01234 = traind[class01234Mask]\n",
    "\n",
    "traind_01234 = traind_01234.reshape(-1,784)\n",
    "\n",
    "print(\"classes 0-4, images: \", trainl_01234.shape)\n",
    "print(\"classes 0-4, labels: \", traind_01234.shape)\n",
    "\n",
    "\n",
    "# classes 5-9\n",
    "class56789Mask = np.logical_or((classVector == 5), \n",
    "                               np.logical_or((classVector == 6), \n",
    "                               np.logical_or((classVector == 7), \n",
    "                               np.logical_or((classVector == 8), \n",
    "                                             (classVector == 9)))))\n",
    "\n",
    "trainl_56789 = trainl[class56789Mask]\n",
    "traind_56789 = traind[class56789Mask]\n",
    "\n",
    "traind_56789 = traind_56789.reshape(-1,784)\n",
    "\n",
    "print(\"classes 5-9, images: \", trainl_56789.shape)\n",
    "print(\"classes 5-9, labels: \", traind_56789.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch creation\n",
    "\n",
    "def get_batch(data, labels, batch_size, index, epoch):\n",
    "    \n",
    "    # if size of traind exceeded, restart!\n",
    "    if index >= (data.shape[0] // batch_size):\n",
    "        index = 0\n",
    "        epoch += 1\n",
    "    \n",
    "    # draw batches\n",
    "    dataBatch = data[index * batch_size:(index+1) * batch_size]\n",
    "    labelBatch = labels[index * batch_size:(index+1) * batch_size]\n",
    "    index += 1\n",
    "    \n",
    "    return dataBatch, labelBatch, index, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_iters = 2000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 784 # MNIST data input (img shape: 28*28)\n",
    "n_hidden_1 = 200 # 1st layer number of neurons\n",
    "n_hidden_2 = 200 # 2st layer number of neurons\n",
    "n_hidden_3 = 200 # 3st layer number of neurons\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='wh1'),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='wh2'),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3]), name='wh3'),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, n_classes]), name='wo')\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1]), name='bh1'),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2]), name='bh2'),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3]), name='bh3'),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]), name='bo')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(x, w, b):\n",
    "    # Hidden fully connected layer with 200 neurons\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, w['h1']), b['b1']))\n",
    "    \n",
    "    # Hidden fully connected layer with 200 neurons\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, w['h2']), b['b2']))\n",
    "    \n",
    "    # Hidden fully connected layer with 200 neurons\n",
    "    layer_3 = tf.nn.relu(tf.add(tf.matmul(layer_2, w['h3']), b['b3']))\n",
    "    \n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.matmul(layer_3, w['out']) + b['out']\n",
    "    \n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_network(X, weights, biases)\n",
    "# prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "update = optimizer.minimize(loss_op)\n",
    "# print(optimizer.compute_gradients(loss_op))\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "# Start training\n",
    "sess = tf.Session()\n",
    "# Run the initializer\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Epoch: 0, Minibatch Loss= 22747.2266, Training Accuracy= 0.234\n",
      "Step 1, Epoch: 0, Minibatch Loss= 26368.9648, Training Accuracy= 0.484\n",
      "Step 100, Epoch: 0, Minibatch Loss= 123.1363, Training Accuracy= 0.945\n",
      "Step 200, Epoch: 0, Minibatch Loss= 60.0898, Training Accuracy= 0.953\n",
      "Step 300, Epoch: 1, Minibatch Loss= 55.1753, Training Accuracy= 0.953\n",
      "Step 400, Epoch: 1, Minibatch Loss= 25.5581, Training Accuracy= 0.977\n",
      "Step 500, Epoch: 2, Minibatch Loss= 16.7239, Training Accuracy= 0.992\n",
      "Step 600, Epoch: 2, Minibatch Loss= 29.8613, Training Accuracy= 0.969\n",
      "Step 700, Epoch: 2, Minibatch Loss= 23.9550, Training Accuracy= 0.977\n",
      "Step 800, Epoch: 3, Minibatch Loss= 26.1366, Training Accuracy= 0.961\n",
      "Step 900, Epoch: 3, Minibatch Loss= 2.0685, Training Accuracy= 0.992\n",
      "Step 1000, Epoch: 4, Minibatch Loss= 2.9668, Training Accuracy= 0.992\n",
      "Step 1100, Epoch: 4, Minibatch Loss= 3.6881, Training Accuracy= 0.992\n",
      "Step 1200, Epoch: 5, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 1300, Epoch: 5, Minibatch Loss= 39.1650, Training Accuracy= 0.977\n",
      "Step 1400, Epoch: 5, Minibatch Loss= 2.1173, Training Accuracy= 0.992\n",
      "Step 1500, Epoch: 6, Minibatch Loss= 0.3409, Training Accuracy= 0.992\n",
      "Step 1600, Epoch: 6, Minibatch Loss= 4.8587, Training Accuracy= 0.984\n",
      "Step 1700, Epoch: 7, Minibatch Loss= 0.8353, Training Accuracy= 0.992\n",
      "Step 1800, Epoch: 7, Minibatch Loss= 1.9223, Training Accuracy= 0.992\n",
      "Step 1900, Epoch: 7, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n"
     ]
    }
   ],
   "source": [
    "# train classes 0-4\n",
    "\n",
    "iteration = 0\n",
    "epoch = 0\n",
    "for step in range(0, training_iters):\n",
    "    batch_x, batch_y, iteration, epoch = get_batch(traind_01234, trainl_01234, batch_size, iteration, epoch)\n",
    "\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(update, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        print(\"Step \" + str(step) + \\\n",
    "              \", Epoch: \" + str(epoch) + \\\n",
    "              \", Minibatch Loss= \" + \\\n",
    "              \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.3f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.4942\n"
     ]
    }
   ],
   "source": [
    "# show accuracy\n",
    "print(\"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={X: testd,\n",
    "                                      Y: testl}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Epoch: 0, Minibatch Loss= 2061.1802, Training Accuracy= 0.180\n",
      "Step 1, Epoch: 0, Minibatch Loss= 1146.1792, Training Accuracy= 0.406\n",
      "Step 100, Epoch: 0, Minibatch Loss= 142.4723, Training Accuracy= 0.891\n",
      "Step 200, Epoch: 0, Minibatch Loss= 39.8204, Training Accuracy= 0.906\n",
      "Step 300, Epoch: 1, Minibatch Loss= 24.3947, Training Accuracy= 0.953\n",
      "Step 400, Epoch: 1, Minibatch Loss= 55.2888, Training Accuracy= 0.914\n",
      "Step 500, Epoch: 2, Minibatch Loss= 47.3211, Training Accuracy= 0.930\n",
      "Step 600, Epoch: 2, Minibatch Loss= 23.4015, Training Accuracy= 0.969\n",
      "Step 700, Epoch: 3, Minibatch Loss= 29.6355, Training Accuracy= 0.961\n",
      "Step 800, Epoch: 3, Minibatch Loss= 7.5735, Training Accuracy= 0.961\n",
      "Step 900, Epoch: 3, Minibatch Loss= 2.5853, Training Accuracy= 0.969\n",
      "Step 1000, Epoch: 4, Minibatch Loss= 31.3688, Training Accuracy= 0.953\n",
      "Step 1100, Epoch: 4, Minibatch Loss= 1.1159, Training Accuracy= 0.992\n",
      "Step 1200, Epoch: 5, Minibatch Loss= 21.0131, Training Accuracy= 0.961\n",
      "Step 1300, Epoch: 5, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 1400, Epoch: 6, Minibatch Loss= 5.9932, Training Accuracy= 0.977\n",
      "Step 1500, Epoch: 6, Minibatch Loss= 11.8784, Training Accuracy= 0.977\n",
      "Step 1600, Epoch: 6, Minibatch Loss= 8.3213, Training Accuracy= 0.984\n",
      "Step 1700, Epoch: 7, Minibatch Loss= 25.5646, Training Accuracy= 0.945\n",
      "Step 1800, Epoch: 7, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Step 1900, Epoch: 8, Minibatch Loss= 1.9188, Training Accuracy= 0.977\n"
     ]
    }
   ],
   "source": [
    "# train classes 5-9\n",
    "\n",
    "iteration = 0\n",
    "epoch = 0\n",
    "for step in range(0, training_iters):\n",
    "    batch_x, batch_y, iteration, epoch = get_batch(traind_56789, trainl_56789, batch_size, iteration, epoch)\n",
    "\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(update, feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "    if step % display_step == 0 or step == 1:\n",
    "        # Calculate batch loss and accuracy\n",
    "        loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y})\n",
    "\n",
    "        print(\"Step \" + str(step) + \\\n",
    "              \", Epoch: \" + str(epoch) + \\\n",
    "              \", Minibatch Loss= \" + \\\n",
    "              \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.3f}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.4588\n"
     ]
    }
   ],
   "source": [
    "# show accuracy\n",
    "print(\"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={X: testd,\n",
    "                                      Y: testl}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
